rows.s2.wad = as.character(df.s2$subject) == as.character(subj) & df.s2$attribute == cur.att & df.s2$type == 'wad_att_rating'
rows.s2.ew = as.character(df.s2$subject) == as.character(subj) & df.s2$attribute == cur.att & df.s2$type == 'ew_att_rating'
rows.s2.lex = as.character(df.s2$subject) == as.character(subj) & df.s2$attribute == cur.att & df.s2$type == 'lex_att_rating'
rows.att.alignment.wad = as.character(df.s2$subject) == as.character(subj) & df.s2$attribute == cur.att & df.s2$type == 'att_alignment_rating'
rows.att.alignment.ew = as.character(df.s2$subject) == as.character(subj) & df.s2$attribute == cur.att & df.s2$type == 'ew_att_alignment_rating'
rows.att.alignment.lex = as.character(df.s2$subject) == as.character(subj) & df.s2$attribute == cur.att & df.s2$type == 'lex_att_alignment_rating'
rows.att.feedback = as.character(df.s2$subject) == as.character(subj) & df.s2$attribute == cur.att & df.s2$type == 'feedback_att'
# if this is the one...
if (any(rows.s2.lex)) {
df.attributes.askabout$reported.weight.single[i] = df.s2$rating[rows.s2.lex]
} else {
df.attributes.askabout$reported.weight.single[i] = 0
}
if (any(rows.s2.ew)) {
df.attributes.askabout$reported.weight.binary[i] = df.s2$rating[rows.s2.ew]
} else {
df.attributes.askabout$reported.weight.binary[i] = 0
}
if (any(rows.s2.wad)) {
df.attributes.askabout$reported.weight.graded[i] = (df.s2$rating[rows.s2.wad] - 50) / 50
} else {
df.attributes.askabout$reported.weight.graded[i] = NA
}
if (any(rows.att.alignment.wad)) {
df.attributes.askabout$ideal.weight.graded[i] = (df.s2$rating[rows.att.alignment.wad] - 50) / 50
} else {
df.attributes.askabout$ideal.weight.graded[i] = NA
}
if (any(rows.att.alignment.ew)) {
df.attributes.askabout$ideal.weight.binary[i] = df.s2$rating[rows.att.alignment.ew]
} else {
df.attributes.askabout$ideal.weight.binary[i] = 0
}
if (any(rows.att.alignment.lex)) {
df.attributes.askabout$ideal.weight.single[i] = df.s2$rating[rows.att.alignment.lex]
} else {
df.attributes.askabout$ideal.weight.single[i] = 0
}
if (any(rows.att.feedback)) {
df.attributes.askabout$feedback.weight[i] = ifelse(df.attributes.askabout$condition[i] == 'real',
df.s2$fitted_weight[rows.att.feedback],
df.s2$fitted_weight_fake[rows.att.feedback])
} else {
df.attributes.askabout$feedback.weight[i] = NA
}
df.attributes.askabout$reported.h1[i] = df.demo$reported.h1[rows.demo]
df.attributes.askabout$reported.h2[i] = df.demo$reported.h2[rows.demo]
df.attributes.askabout$reported.h3[i] = df.demo$reported.h3[rows.demo]
df.attributes.askabout$reported.h1.dichotomized[i] = df.demo$reported.h1.dichotomized[rows.demo]
df.attributes.askabout$reported.h2.dichotomized[i] = df.demo$reported.h2.dichotomized[rows.demo]
df.attributes.askabout$reported.h3.dichotomized[i] = df.demo$reported.h3.dichotomized[rows.demo]
df.attributes.askabout$reported.model[i] = df.demo$reported.model[rows.demo]
df.attributes.askabout$reported.model.num[i] = df.demo$reported.model.num[rows.demo]
df.attributes.askabout$reported.model.fac[i] = df.demo$reported.model.fac[rows.demo]
df.attributes.askabout$reported.weight.reported[i] = ifelse(df.demo$reported.h1.dichotomized[rows.demo] == 'One',
df.attributes.askabout$reported.weight.single[i],
ifelse(df.demo$reported.h2.dichotomized[rows.demo] == 'Binary',
df.attributes.askabout$reported.weight.binary[i],
df.attributes.askabout$reported.weight.graded[i]))
df.attributes.askabout$ideal.weight.reported[i] = ifelse(df.demo$reported.h1.dichotomized[rows.demo] == 'One',
df.attributes.askabout$ideal.weight.single[i],
ifelse(df.demo$reported.h2.dichotomized[rows.demo] == 'Binary',
df.attributes.askabout$ideal.weight.binary[i],
df.attributes.askabout$ideal.weight.graded[i]))
df.attributes.askabout$dating_summary[i] = as.character(df.demo$dating_summary[rows.demo])
df.attributes.askabout$gender[i] = df.demo$gender[rows.demo]
df.attributes.askabout$political_orientation.split[i] = df.demo$political_orientation.split[rows.demo]
}
df.attributes.askabout = df.attributes.askabout %>%
mutate(reported.weight.graded.signed = reported.weight.graded,
reported.weight.binary.signed = reported.weight.binary,
reported.weight.single.signed = reported.weight.single,
reported.weight.reported.signed = reported.weight.reported,
ideal.weight.graded.signed = ideal.weight.graded,
ideal.weight.binary.signed = ideal.weight.binary,
ideal.weight.single.signed = ideal.weight.single,
ideal.weight.reported.signed = ideal.weight.reported,
attribute.fac = factor(attribute, atts.askabout, atts.askabout),
explicit = sub_of %in% c('', 'NULL', NULL),
#dating.summary = factor(dating.summary, c('Partnered', 'Single and not seeking', 'Single and seeking')),
gender.fac = factor(gender, c('Man', 'Woman', 'Some other way', 'Prefer not to say'), c('Man', 'Woman', 'Other', 'Other')),
political_orientation.fac = factor(political_orientation.split, c('Conservative', 'Moderate', 'Liberal')))
## Save some data that we need to analyze the observer data
# (this gets saved to the observers folder)
if (has_observers) {
write.table(df.demo %>% select(subject, subject.num), paste0(filepath_observer, 'observer_mapping.csv'), row.names = F, col.names = F, sep = ",")
write.table(atts, paste0(filepath_observer, 'att_order.csv'), row.names = F, col.names = F, sep = ",")
}
if (timepoint == "") {
save.image(paste0(filepath, 'analysis_output.rdata'))
} else {
save.image(paste0(filepath, 'analysis_output_', timepoint, '.rdata'))
# save data for test-retest
if (timepoint == 't1' && exists("df.demo.filt")) {
df.demo.t1 = df.demo.filt
df.attributes.askabout.t1 = df.attributes.askabout.filt
save(df.demo.t1, df.attributes.askabout.t1, file = paste0(filepath, 'analysis_output_', timepoint, '_limited.rdata'))
}
}
rm(list=ls())
# Setup -------------------------------------------------------------
if (!require('pacman')) {
install.packages('pacman')
require('pacman')
}
p_load(this.path, parallel, matrixStats, dplyr)
# Set version -------------------------------------------------------------
## which version do we want?
# note that we don't fit observers
versions = c('pilot1', 'pilot2', 'pilot3', 'pilot4')
version = versions[4]
timepoint = 't1' # t1, t2, or ""
## which trials do we want?
trial.kinds.fitting = c('all', 'even', 'odd', 'firsthalf', 'secondhalf')
trial.kind.fitting = trial.kinds.fitting[1]
input.filepath = paste0(here(), '/', version, '/')
if (timepoint == "") {
output.filepath = paste0(input.filepath, 'modeling-output/', trial.kind.fitting, '/')
load(paste0(input.filepath,'analysis_output.rdata'))
} else {
output.filepath = paste0(input.filepath, 'modeling-output/', timepoint, '/', trial.kind.fitting, '/')
load(paste0(input.filepath,'analysis_output_', timepoint, '.rdata'))
}
if (trial.kind.fitting == 'all') {
trials.touse = 0:(numTrials-1)
} else if (trial.kind.fitting == 'even') {
trials.touse = seq(0,numTrials-1,2)
} else if (trial.kind.fitting == 'odd') {
trials.touse = seq(1,numTrials-1,2)
} else if (trial.kind.fitting == 'firsthalf') {
trials.touse = 0:floor(((numTrials-1) / 2))
} else if (trial.kind.fitting == 'secondhalf') {
trials.touse = ceiling(((numTrials-1) / 2)):(numTrials-1)
}
numSubj = 6#length(subjlist)
numAtts.touse = numAtts.askabout.subj
numTrials.touse = length(trials.touse)
source(paste0(here(),'/model-fitting/model-fitting.R'))
stan_model_full <- stan_model(paste0(here(),"/model-fitting/stan-program.stan"))
stan_model_binwts <- stan_model(paste0(here(),"/model-fitting/stan-program-binwts.stan"))
# Do model-fitting --------------------------------------------------------
numCores = 6
option_diffs_allsubj = vector(mode = 'list', numSubj)
for (subj in 1:numSubj) {
if (timepoint != '' && any(df.s1$timepoint[df.s1$subject.num == subj] != timepoint)) stop("Timepoint in df.s1 doesn't match stated timepoint.")
atts.subj = (df.attributes.askabout %>% filter(subject.num == subj))$attribute
atts.askabout.opt.scaled.diff[which(atts.askabout %in% atts.subj)]
option_diffs_allsubj[[subj]] = t(as.matrix(df.s1 %>%
filter(subject.num == subj, trial %in% trials.touse) %>%
select(all_of(atts.askabout.opt.scaled.diff[which(atts.askabout %in% atts.subj)]))))
}
option_diffs_touse = option_diffs_allsubj
#save(option_diffs_allsubj, file = paste0(here(), '/model-fitting/option_diffs.rdata')) # save for simulations
choices_touse = vector(mode = 'list', numSubj)
for (subj in 1:numSubj) {
choices_touse[[subj]] = df.s1 %>%
filter(subject.num == subj & trial %in% trials.touse) %>%
pull(choice)
}
# for debugging
#fitSubj(stan_model_full, option_diffs_touse[[1]], choices_touse[[1]], 0, 0, numTrials.touse, full_output = TRUE)
## FIT FULL
fitting_results = mclapply(
1:numSubj,
function(subj) {return(fitAllModels(option_diffs_touse[[subj]], choices_touse[[subj]], length(choices_touse[[subj]]), full_output = TRUE))},
mc.cores = numCores
)
# Split so that each saved data file is <100mb
fitting_results_split = split(fitting_results, ceiling(seq_along(fitting_results) / 20))
for (i in 1:length(fitting_results_split)) {
fitting_results_split_cur = fitting_results_split[[i]]
save(numAtts.touse, #option_diffs_touse, choices_touse, data.filepath,
stan.seed, numChains, numIter, fitSubj,
fitting_results_split_cur,
file = paste0(output.filepath, 'modeling_output_', i, '.rdata'))
}
rnorm(2)
df.part2.atts = df.attributes.askabout %>%
filter(
subject %in% df.part2.demo$subject,
in_top5
) %>%
select(subject, version, attribute,
fitted.weight.averaged, reported.weight.graded.signed,
#reporting.error,
potential, in_top5) %>%
ungroup() %>%
# mutate(reporting.error.shuffled = sample(reporting.error),
#        fitted.weight.fake = reported.weight.graded.signed - reporting.error.shuffled) %>%
mutate(fitted.weight.fake = reported.weight.graded.signed + rnorm(1, mean = 0, sd = 0.15))
rm(list=ls())
load("/Users/am9578/My Drive/Psychology/Projects/ma_choice_okcupid/git/alignment_causal/v2/pilot4/analysis_output_t1.rdata")
# for part 2
df.part2.demo = df.demo.filt %>%
select(subject, version, attribute_set_used, attraction,
reported.h1, reported.h2, reported.h3,
actual.h1.prob, actual.h2.prob, actual.h3.prob,
strat_q_order, which_face_list, face_id_list_time2,
top5_min_potential) %>%
mutate(attribute_set_touse = attribute_set_used) %>%
filter(top5_min_potential > .01)
# for part 2
df.part2.demo = df.demo %>%
select(subject, version, attribute_set_used, attraction,
reported.h1, reported.h2, reported.h3,
actual.h1.prob, actual.h2.prob, actual.h3.prob,
strat_q_order, which_face_list, face_id_list_time2,
top5_min_potential) %>%
mutate(attribute_set_touse = attribute_set_used) %>%
filter(top5_min_potential > .01)
df.part2.atts = df.attributes.askabout %>%
filter(
#subject %in% df.part2.demo$subject,
in_top5
) %>%
select(subject, version, attribute,
fitted.weight.averaged, reported.weight.graded.signed,
#reporting.error,
potential, in_top5) %>%
ungroup() %>%
# mutate(reporting.error.shuffled = sample(reporting.error),
#        fitted.weight.fake = reported.weight.graded.signed - reporting.error.shuffled) %>%
mutate(fitted.weight.fake = reported.weight.graded.signed + rnorm(1, mean = 0, sd = 0.15))
rm(list=ls())
# Setup -------------------------------------------------------------
if (!require('pacman')) {
install.packages('pacman')
require('pacman')
}
p_load(this.path, parallel, matrixStats, dplyr)
# Set version -------------------------------------------------------------
## which version do we want?
# note that we don't fit observers
versions = c('pilot1', 'pilot2', 'pilot3', 'pilot4')
version = versions[4]
timepoint = 't1' # t1, t2, or ""
## which trials do we want?
trial.kinds.fitting = c('all', 'even', 'odd', 'firsthalf', 'secondhalf')
trial.kind.fitting = trial.kinds.fitting[1]
input.filepath = paste0(here(), '/', version, '/')
if (timepoint == "") {
output.filepath = paste0(input.filepath, 'modeling-output/', trial.kind.fitting, '/')
load(paste0(input.filepath,'analysis_output.rdata'))
} else {
output.filepath = paste0(input.filepath, 'modeling-output/', timepoint, '/', trial.kind.fitting, '/')
load(paste0(input.filepath,'analysis_output_', timepoint, '.rdata'))
}
if (trial.kind.fitting == 'all') {
trials.touse = 0:(numTrials-1)
} else if (trial.kind.fitting == 'even') {
trials.touse = seq(0,numTrials-1,2)
} else if (trial.kind.fitting == 'odd') {
trials.touse = seq(1,numTrials-1,2)
} else if (trial.kind.fitting == 'firsthalf') {
trials.touse = 0:floor(((numTrials-1) / 2))
} else if (trial.kind.fitting == 'secondhalf') {
trials.touse = ceiling(((numTrials-1) / 2)):(numTrials-1)
}
numSubj = length(subjlist)
numAtts.touse = numAtts.askabout.subj
numTrials.touse = length(trials.touse)
source(paste0(here(),'/model-fitting/model-fitting.R'))
stan_model_full <- stan_model(paste0(here(),"/model-fitting/stan-program.stan"))
stan_model_binwts <- stan_model(paste0(here(),"/model-fitting/stan-program-binwts.stan"))
# Do model-fitting --------------------------------------------------------
numCores = 6
option_diffs_allsubj = vector(mode = 'list', numSubj)
for (subj in 1:numSubj) {
if (timepoint != '' && any(df.s1$timepoint[df.s1$subject.num == subj] != timepoint)) stop("Timepoint in df.s1 doesn't match stated timepoint.")
atts.subj = (df.attributes.askabout %>% filter(subject.num == subj))$attribute
atts.askabout.opt.scaled.diff[which(atts.askabout %in% atts.subj)]
option_diffs_allsubj[[subj]] = t(as.matrix(df.s1 %>%
filter(subject.num == subj, trial %in% trials.touse) %>%
select(all_of(atts.askabout.opt.scaled.diff[which(atts.askabout %in% atts.subj)]))))
}
option_diffs_touse = option_diffs_allsubj
#save(option_diffs_allsubj, file = paste0(here(), '/model-fitting/option_diffs.rdata')) # save for simulations
choices_touse = vector(mode = 'list', numSubj)
for (subj in 1:numSubj) {
choices_touse[[subj]] = df.s1 %>%
filter(subject.num == subj & trial %in% trials.touse) %>%
pull(choice)
}
# for debugging
#fitSubj(stan_model_full, option_diffs_touse[[1]], choices_touse[[1]], 0, 0, numTrials.touse, full_output = TRUE)
## FIT FULL
fitting_results = mclapply(
1:numSubj,
function(subj) {return(fitAllModels(option_diffs_touse[[subj]], choices_touse[[subj]], length(choices_touse[[subj]]), full_output = TRUE))},
mc.cores = numCores
)
# Split so that each saved data file is <100mb
fitting_results_split = split(fitting_results, ceiling(seq_along(fitting_results) / 20))
for (i in 1:length(fitting_results_split)) {
fitting_results_split_cur = fitting_results_split[[i]]
save(numAtts.touse, #option_diffs_touse, choices_touse, data.filepath,
stan.seed, numChains, numIter, fitSubj,
fitting_results_split_cur,
file = paste0(output.filepath, 'modeling_output_', i, '.rdata'))
}
rm(list=ls())
library(tidyverse)
library(brms)
library(furrr)
library(progressr)
library(this.path)
set.seed(2025)
setwd(here())
# Fit logistic regressiona for all scenarios for a given model.
analyze_model <- function(
model_name,
latent = FALSE,
n_workers = 6) {
selections_path <- paste0("data/", model_name, "_instilled_selections.csv")
if (latent) {
selections_path <- str_replace(selections_path, "selections", "latent_selections")
}
selections <- read_csv(selections_path)
scenarios <-
read_csv("data/scenarios.csv") %>%
mutate(
attr1_range = attr1_max - attr1_min,
attr2_range = attr2_max - attr2_min,
attr3_range = attr3_max - attr3_min,
attr4_range = attr4_max - attr4_min,
attr5_range = attr5_max - attr5_min
)
regression_data <-
selections %>%
left_join(scenarios, by = "scenario") %>%
mutate(
selection = ifelse(selection == "A", 1, 0),
attr1_diff_normalized = (A_attribute_1 - B_attribute_1) / attr1_range,
attr2_diff_normalized = (A_attribute_2 - B_attribute_2) / attr2_range,
attr3_diff_normalized = (A_attribute_3 - B_attribute_3) / attr3_range,
attr4_diff_normalized = (A_attribute_4 - B_attribute_4) / attr4_range,
attr5_diff_normalized = (A_attribute_5 - B_attribute_5) / attr5_range
)
# Compile an initial model once (so that we don't have to compile for each scenario).
brm_model <- brm(
selection ~ attr1_diff_normalized + attr2_diff_normalized +
attr3_diff_normalized + attr4_diff_normalized + attr5_diff_normalized,
data = filter(regression_data, scenario == first(scenario)),
family = "bernoulli",
prior(normal(0, 1), class = b), # To prevent these terms from exploding
)
safe_brm_fit <- function(data_subset) {
warnings <- character()
results <- withCallingHandlers(
{
fit <- update(brm_model, newdata = data_subset)
posterior_summary(fit) %>%
as_tibble(rownames = "term") %>%
filter(str_detect(term, "attr"))
},
warning = function(w) {
warnings <<- c(warnings, conditionMessage(w))
invokeRestart("muffleWarning")
},
error = function(e) {
return(list(
error = TRUE,
message = as.character(e),
results = NULL,
warnings = warnings
))
}
)
list(
error = FALSE,
results = results,
warnings = warnings
)
}
# Process data in parallel.
handlers(global = TRUE)
handlers("progress")
plan(multisession, workers = n_workers)
set.seed(1)
total_steps <- n_distinct(regression_data$scenario)
with_progress({
p <- progressor(steps = total_steps)
brm_results_parallel_normal <-
regression_data %>%
filter(!flipped) %>%
group_by(scenario) %>%
group_split() %>%
future_map_dfr(
~ {
current_scenario <- first(.x$scenario)
p(sprintf("Processing scenario %s", current_scenario))
results <- safe_brm_fit(.x)
if (results$error) {
tibble(
scenario = first(.x$scenario),
error = TRUE,
warnings = list(results$warnings),
error_message = results$message,
term = NA_character_,
Estimate = NA_real_
)
} else {
results$results %>%
mutate(
scenario = first(.x$scenario),
error = FALSE,
warnings = list(results$warnings)
)
}
},
.options = furrr_options(seed = TRUE)
)
brm_results_parallel_flipped <-
regression_data %>%
filter(flipped) %>%
group_by(scenario) %>%
group_split() %>%
future_map_dfr(
~ {
current_scenario <- first(.x$scenario)
p(sprintf("Processing scenario %s", current_scenario))
results <- safe_brm_fit(.x)
if (results$error) {
tibble(
scenario = first(.x$scenario),
error = TRUE,
warnings = list(results$warnings),
error_message = results$message,
term = NA_character_,
Estimate = NA_real_
)
} else {
results$results %>%
mutate(
scenario = first(.x$scenario),
error = FALSE,
warnings = list(results$warnings)
)
}
},
.options = furrr_options(seed = TRUE)
)
})
# Process results.
cases_with_warnings_normal <-
brm_results_parallel_normal %>%
filter(map_lgl(warnings, ~ length(.x) > 0)) %>%
select(scenario, warnings) %>%
distinct() %>%
mutate(warning_messages = map_chr(warnings, ~ paste(.x, collapse = "; "))) %>%
select(-warnings)
cases_with_warnings_flipped <-
brm_results_parallel_flipped %>%
filter(map_lgl(warnings, ~ length(.x) > 0)) %>%
select(scenario, warnings) %>%
distinct() %>%
mutate(warning_messages = map_chr(warnings, ~ paste(.x, collapse = "; "))) %>%
select(-warnings)
successful_fits_normal <-
brm_results_parallel_normal %>%
filter(!error & map_lgl(warnings, ~ length(.x) == 0)) %>%
select(-warnings, -error) %>%
select(scenario, term, Estimate) %>%
pivot_wider(names_from = term, values_from = Estimate) %>%
rename_with(~ str_replace(., "_diff_normalized", ""))
successful_fits_flipped <-
brm_results_parallel_flipped %>%
filter(!error & map_lgl(warnings, ~ length(.x) == 0)) %>%
select(-warnings, -error) %>%
select(scenario, term, Estimate) %>%
pivot_wider(names_from = term, values_from = Estimate) %>%
rename_with(~ str_replace(., "_diff_normalized", ""))
results_normalized_normal <-
successful_fits_normal %>%
rowwise() %>%
mutate(
max_abs_idx = which.max(abs(c(b_attr1, b_attr2, b_attr3, b_attr4, b_attr5))),
max_signed = c(b_attr1, b_attr2, b_attr3, b_attr4, b_attr5)[max_abs_idx],
max_sign = sign(max_signed),
across(starts_with("b_attr"), ~ round(. / max_signed * 100 * max_sign))
) %>%
select(-max_abs_idx, -max_signed, -max_sign)
results_normalized_flipped <-
successful_fits_flipped %>%
rowwise() %>%
mutate(
max_abs_idx = which.max(abs(c(b_attr1, b_attr2, b_attr3, b_attr4, b_attr5))),
max_signed = c(b_attr1, b_attr2, b_attr3, b_attr4, b_attr5)[max_abs_idx],
max_sign = sign(max_signed),
across(starts_with("b_attr"), ~ round(. / max_signed * 100 * max_sign))
) %>%
select(-max_abs_idx, -max_signed, -max_sign)
# Save results.
outfile_path_normal <- paste0("data/", model_name, "_regression_results_normal.csv")
if (latent) {
outfile_path_normal <- str_replace(outfile_path_normal, "regression", "latent_regression")
}
write_csv(results_normalized_normal, outfile_path_normal)
outfile_path_flipped <- paste0("data/", model_name, "_regression_results_flipped.csv")
if (latent) {
outfile_path_flipped <- str_replace(outfile_path_flipped, "regression", "latent_regression")
}
write_csv(results_normalized_flipped, outfile_path_flipped)
# Return results and warnings.
list(
results_normal = results_normalized_normal,
results_flipped = results_normalized_flipped,
warnings_normal = cases_with_warnings_normal,
warnings_flipped = cases_with_warnings_flipped
)
}
analyze_model("gpt-4.1-2025-04-14_20_instilled_prefs_150ex_10flipscenarios")
